{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploracion del Dataset: Old Book Illustrations\n",
    "\n",
    "Analizamos el dataset `gigant/oldbookillustrations` para entender su estructura\n",
    "y definir las transformaciones necesarias para el fine-tuning de Stable Diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cargar dataset y ver columnas disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"gigant/oldbookillustrations\"\n",
    "dataset = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "print(f\"Numero de muestras: {len(dataset)}\")\n",
    "print(f\"Columnas: {dataset.column_names}\")\n",
    "print(f\"\\nEjemplo de una fila:\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analizar tamanos de imagenes\n",
    "\n",
    "**Punto clave:** A diferencia del dataset Pokemon del docente (imagenes cuadradas),\n",
    "las ilustraciones de libros antiguos tienen proporciones variadas. Esto afecta\n",
    "directamente a como definimos las transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recopilar tamanos de todas las imagenes\n",
    "widths = []\n",
    "heights = []\n",
    "aspect_ratios = []\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    img = dataset[i][\"1600px\"]\n",
    "    w, h = img.size\n",
    "    widths.append(w)\n",
    "    heights.append(h)\n",
    "    aspect_ratios.append(w / h)\n",
    "\n",
    "print(f\"Ancho  - min: {min(widths)}, max: {max(widths)}, media: {np.mean(widths):.0f}\")\n",
    "print(f\"Alto   - min: {min(heights)}, max: {max(heights)}, media: {np.mean(heights):.0f}\")\n",
    "print(f\"Aspect ratio - min: {min(aspect_ratios):.2f}, max: {max(aspect_ratios):.2f}, media: {np.mean(aspect_ratios):.2f}\")\n",
    "\n",
    "# Cuantas son cuadradas?\n",
    "cuadradas = sum(1 for w, h in zip(widths, heights) if w == h)\n",
    "print(f\"\\nImagenes cuadradas: {cuadradas}/{len(dataset)} ({100*cuadradas/len(dataset):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de tamanos\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(widths, bins=30, color='steelblue', edgecolor='black')\n",
    "axes[0].set_title('Distribucion de anchos')\n",
    "axes[0].set_xlabel('Ancho (px)')\n",
    "\n",
    "axes[1].hist(heights, bins=30, color='coral', edgecolor='black')\n",
    "axes[1].set_title('Distribucion de altos')\n",
    "axes[1].set_xlabel('Alto (px)')\n",
    "\n",
    "axes[2].hist(aspect_ratios, bins=30, color='mediumseagreen', edgecolor='black')\n",
    "axes[2].set_title('Distribucion de aspect ratios')\n",
    "axes[2].set_xlabel('Aspect Ratio (w/h)')\n",
    "axes[2].axvline(x=1.0, color='red', linestyle='--', label='Cuadrada')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizar muestras con sus captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar 8 muestras del dataset\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "indices = np.random.choice(len(dataset), 8, replace=False)\n",
    "\n",
    "for ax, idx in zip(axes.flat, indices):\n",
    "    example = dataset[int(idx)]\n",
    "    img = example[\"1600px\"]\n",
    "    caption = example[\"info_alt\"]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(caption[:60] + \"...\" if len(caption) > 60 else caption, fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Muestras del dataset Old Book Illustrations', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparar transformaciones\n",
    "\n",
    "Comparamos dos estrategias de resize:\n",
    "- **Resize(512, 512):** Estira la imagen. Es lo que usa el docente con Pokemon (imagenes ya cuadradas).\n",
    "- **Resize(512) + CenterCrop(512):** Primero redimensiona el lado menor a 512, luego recorta el centro. Preserva proporciones.\n",
    "\n",
    "Para imagenes no cuadradas como las de este dataset, la segunda opcion es mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las dos transformaciones\n",
    "transform_stretch = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_crop = transforms.Compose([\n",
    "    transforms.Resize(512),\n",
    "    transforms.CenterCrop(512),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Comparar con 4 imagenes del dataset\n",
    "fig, axes = plt.subplots(4, 3, figsize=(15, 20))\n",
    "\n",
    "sample_indices = [0, 10, 50, 100]\n",
    "for row, idx in enumerate(sample_indices):\n",
    "    img = dataset[idx][\"1600px\"].convert(\"RGB\")\n",
    "    w, h = img.size\n",
    "    \n",
    "    stretched = transforms.ToPILImage()(transform_stretch(img))\n",
    "    cropped = transforms.ToPILImage()(transform_crop(img))\n",
    "    \n",
    "    axes[row, 0].imshow(img)\n",
    "    axes[row, 0].set_title(f'Original ({w}x{h})', fontsize=10)\n",
    "    axes[row, 0].axis('off')\n",
    "    \n",
    "    axes[row, 1].imshow(stretched)\n",
    "    axes[row, 1].set_title('Resize(512,512) - Estira', fontsize=10)\n",
    "    axes[row, 1].axis('off')\n",
    "    \n",
    "    axes[row, 2].imshow(cropped)\n",
    "    axes[row, 2].set_title('Resize(512) + CenterCrop(512)', fontsize=10)\n",
    "    axes[row, 2].axis('off')\n",
    "\n",
    "plt.suptitle('Comparacion de transformaciones', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verificar integridad del dataset\n",
    "\n",
    "Comprobamos que no hay imagenes rotas ni captions vacias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar integridad\n",
    "resolution = 512\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(resolution),\n",
    "    transforms.CenterCrop(resolution),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "errores = 0\n",
    "captions_vacios = 0\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    example = dataset[i]\n",
    "    \n",
    "    # Verificar caption\n",
    "    caption = example[\"info_alt\"]\n",
    "    if not caption or caption.strip() == \"\":\n",
    "        captions_vacios += 1\n",
    "    \n",
    "    # Verificar imagen\n",
    "    try:\n",
    "        img = example[\"1600px\"].convert(\"RGB\")\n",
    "        tensor = image_transforms(img)\n",
    "        assert tensor.shape == (3, 512, 512)\n",
    "    except Exception as e:\n",
    "        print(f\"Error en muestra {i}: {e}\")\n",
    "        errores += 1\n",
    "\n",
    "print(f\"\\nResultados de verificacion:\")\n",
    "print(f\"  Total muestras: {len(dataset)}\")\n",
    "print(f\"  Imagenes con error: {errores}\")\n",
    "print(f\"  Captions vacios: {captions_vacios}\")\n",
    "print(f\"  Todas las imagenes se procesan correctamente: {errores == 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "1. Las imagenes del dataset **no son cuadradas** (a diferencia del dataset Pokemon del docente).\n",
    "2. Usaremos `Resize(512) + CenterCrop(512)` en vez de `Resize((512, 512))` para no distorsionar.\n",
    "3. La columna de imagen es `\"1600px\"` (en vez de `\"image\"` del Pokemon).\n",
    "4. La columna de caption es `\"info_alt\"` (en vez de `\"text\"` del Pokemon).\n",
    "5. Todas las muestras se procesan correctamente con la transformacion elegida."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
