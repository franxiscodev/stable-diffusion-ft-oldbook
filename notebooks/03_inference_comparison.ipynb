{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencia y Comparacion: Antes vs Despues del Fine-tuning\n",
    "\n",
    "Comparamos las imagenes generadas por Stable Diffusion v1-4 antes y despues\n",
    "del fine-tuning con el dataset Old Book Illustrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "from diffusers import UNet2DConditionModel\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pretrained_model_name = \"CompVis/stable-diffusion-v1-4\"\n",
    "prompt = \"an illustration of a ship sailing through a stormy sea\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Prompt: {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imagen ANTES del fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cargar modelo base\npipe = StableDiffusionPipeline.from_pretrained(\n    pretrained_model_name,\n).to(device)\n\nimage_before = pipe(prompt, height=256, width=256).images[0]\nimage_before.save(\"../generated/before_finetuning.png\")\n\nimage_before"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar memoria\n",
    "del pipe\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imagen DESPUES del fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la UNet finetuneada:\n",
    "finetuned_unet = UNet2DConditionModel.from_pretrained(\"../outputs/finetuned-model\")\n",
    "finetuned_unet.to(device)\n",
    "\n",
    "print('Modelo finetuneado cargado correctamente!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cargamos el modelo pre-entrenado pero sustituyendo la UNet por la nuestra:\npipe = StableDiffusionPipeline.from_pretrained(\n    pretrained_model_name,\n    unet=finetuned_unet,\n).to(device)\n\nimage_after = pipe(prompt, height=256, width=256).images[0]\nimage_after.save(\"../generated/after_finetuning.png\")\n\nimage_after"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparacion side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar ambas imagenes (por si se ejecuta esta celda independientemente)\n",
    "image_before = Image.open(\"../generated/before_finetuning.png\")\n",
    "image_after = Image.open(\"../generated/after_finetuning.png\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "axes[0].imshow(image_before)\n",
    "axes[0].set_title('ANTES del fine-tuning', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(image_after)\n",
    "axes[1].set_title('DESPUES del fine-tuning', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.suptitle(f'Prompt: \"{prompt}\"', fontsize=12, style='italic')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../generated/comparison.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Comparacion guardada en ../generated/comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prueba con prompts adicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generar con otros prompts para ver el efecto del fine-tuning\ntest_prompts = [\n    \"a medieval knight riding a horse\",\n    \"a forest with ancient trees and a river\",\n    \"a portrait of an old man with a long beard\",\n]\n\nfig, axes = plt.subplots(len(test_prompts), 1, figsize=(7, 7 * len(test_prompts)))\n\nfor ax, test_prompt in zip(axes, test_prompts):\n    img = pipe(test_prompt, height=256, width=256).images[0]\n    ax.imshow(img)\n    ax.set_title(test_prompt, fontsize=12)\n    ax.axis('off')\n\nplt.suptitle('Imagenes generadas con modelo fine-tuneado', fontsize=14)\nplt.tight_layout()\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}